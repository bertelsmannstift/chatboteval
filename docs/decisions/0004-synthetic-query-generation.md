# 0004 Synthetic Query Generation

Status: Accepted


## Decision

This project supports generating chatbot evaluation queries when real user queries cannot be collected. 

The following architectural constraints apply:

- **Synthetic query generation**
  - Queries are generated by an LLM-driven workflow.
- **Promptless, spec-driven interface**
  - Users provide a small structured query-generation spec (constraints + knobs), not free-form prompts.
  - Prompt templates are internal implementation details and are not part of the user-facing surface.
- **Decouple inputs from outputs via controlled sampling**
  - The number of generated queries is controlled explicitly not tied 1:1 to the number of provided seed items.
  - Output diversity/coverage is enforced via sampling/selection constraints
- **Staged and schema-driven generation**
  - Generation proceeds in two stages:
  1. produce structured candidate specifications (schema-constrained),
  2. realize selected candidates into query text.
- **LLM orchestration framework**
  - LangChain is used for prompt templating, model invocation, and schema-constrained structured outputs at LLM boundaries.
  - The workflow depends on LangChain’s chat model interface rather than a single vendor SDK, enabling configurable backends (local, Hugging Face, hosted APIs).
  - Out of scope: Graph-based / agent-style orchestration (e.g., LangGraph)

## Rationale

- **Synthetic query generation enables dataset construction under data constraints**
  - In many deployments, real user queries cannot be collected due to data protection, contractual, or operational constraints.
- **Promptless, spec-driven interface ensures clarity and separation of concerns**
  - A structured spec reduces user burden, avoids “prompt engineering” as part of the product UX, and cleanly separates user intent from internal implementation.
- **Decoupling inputs from outputs enables controlled scaling and diversity**
  - Treating query generation as a sampling problem allows independent control of output volume and systematic enforcement of coverage and diversity constraints.
- **Staged, schema-driven generation enables enforceable control over generation**
  - Generating free-form text directly makes volume and diversity constraints unenforceable; introducing a structured intermediate representation ensures that candidate queries can be validated, counted, and selected deterministically before surface realization.
- **A framework-level LLM abstraction enforces clean boundaries and flexibility**
  - Using a framework-level LLM abstraction isolates prompt and schema handling at clear boundaries while avoiding lock-in to a single provider and keeping core workflow logic independent of vendor-specific SDKs.

## Consequences

- **A user-facing query generation spec becomes a stable contract**
  - The project must define and maintain a documented query-generation spec.
- **A structured intermediate representation is required**
  - The project must define schemas for candidate specifications
- **Model/provider configuration becomes a supported surface**
  - The workflow must accept a configurable LangChain chat model backend and document supported configuration patterns.
- **No graph/agent orchestration** 
  - The workflow is implemented as a straight-line pipeline; moving to graph/agent orchestration would be a major redesign.
